<div align="center">

# ğŸŒ¸ Iris Flower Classification
### CodeAlpha Data Science Internship â€” Task 1

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626?style=for-the-badge&logo=jupyter&logoColor=white)](https://jupyter.org)
[![Pandas](https://img.shields.io/badge/Pandas-2.0+-150458?style=for-the-badge&logo=pandas&logoColor=white)](https://pandas.pydata.org)
[![Status](https://img.shields.io/badge/Status-âœ…%20Completed-2ecc71?style=for-the-badge)]()
[![Internship](https://img.shields.io/badge/CodeAlpha-Internship-FF6B6B?style=for-the-badge)]()

<br>

> **A complete machine learning pipeline** that classifies Iris flowers into 3 species using 4 classifiers â€” achieving up to **100% test accuracy** with full EDA, evaluation, and visualization.

<br>

[ğŸ““ View Notebook](#-notebook-preview) â€¢ [ğŸ“Š Results](#-results) â€¢ [ğŸš€ How to Run](#-how-to-run) â€¢ [ğŸ“ Project Structure](#-project-structure)

</div>

---

## ğŸ“Œ Project Overview

This project is **Task 1** of the CodeAlpha Data Science Internship. The goal is to build a supervised machine learning model that classifies Iris flowers into one of three species â€” **Setosa**, **Versicolor**, or **Virginica** â€” based on 4 physical measurements.

The project covers the complete ML pipeline from data exploration to model evaluation and comparison, using **4 different classifiers** side-by-side.

---

## ğŸ¯ Objectives

- âœ… Perform thorough Exploratory Data Analysis (EDA) with visualizations
- âœ… Preprocess data with StandardScaler for optimal model performance
- âœ… Train and compare 4 machine learning classifiers
- âœ… Evaluate models using accuracy, cross-validation, and confusion matrices
- âœ… Identify the best model and extract feature importance insights

---

## ğŸ“‚ Dataset

| Property | Detail |
|----------|--------|
| **Source** | UCI Machine Learning Repository (via `sklearn.datasets`) |
| **Samples** | 150 (50 per class) |
| **Features** | 4 â€” Sepal Length, Sepal Width, Petal Length, Petal Width |
| **Target** | 3 classes â€” Setosa, Versicolor, Virginica |
| **Missing Values** | None |
| **Class Balance** | Perfectly balanced (50 samples each) |

<details>
<summary>ğŸ“‹ Feature Description</summary>

| Feature | Unit | Description |
|---------|------|-------------|
| `sepal_length` | cm | Length of the flower's sepal |
| `sepal_width` | cm | Width of the flower's sepal |
| `petal_length` | cm | Length of the flower's petal |
| `petal_width` | cm | Width of the flower's petal |
| `species` | â€” | **Target**: Setosa / Versicolor / Virginica |

</details>

---

## ğŸ› ï¸ Tech Stack

| Tool | Version | Purpose |
|------|---------|---------|
| Python | 3.10+ | Core language |
| Pandas | 2.0+ | Data manipulation |
| NumPy | 1.24+ | Numerical operations |
| Scikit-learn | 1.3+ | ML models & evaluation |
| Matplotlib | 3.7+ | Visualizations |
| Seaborn | 0.12+ | Statistical plots |
| Jupyter Notebook | â€” | Development environment |

---

## ğŸ¤– Models Used

| # | Model | Key Hyperparameters |
|---|-------|---------------------|
| 1 | **Logistic Regression** | `max_iter=300` |
| 2 | **Decision Tree** | `max_depth=4` |
| 3 | **Random Forest** | `n_estimators=100`, `max_depth=5` |
| 4 | **K-Nearest Neighbors (KNN)** | `n_neighbors=5`, `metric='euclidean'` |

All models evaluated with:
- **80/20 Train-Test Split** (stratified)
- **5-Fold Stratified Cross-Validation**
- StandardScaler normalization applied

---

## ğŸ“Š Results

| Rank | Model | Test Accuracy | CV Mean | CV Std |
|------|-------|:-------------:|:-------:|:------:|
| ğŸ¥‡ | Random Forest | **~97â€“100%** | ~96% | Â±2% |
| ğŸ¥ˆ | KNN | ~96â€“100% | ~95% | Â±3% |
| ğŸ¥‰ | Logistic Regression | ~96â€“97% | ~95% | Â±3% |
| 4 | Decision Tree | ~93â€“97% | ~93% | Â±4% |

> ğŸ’¡ *Exact values depend on the random seed. Run the notebook to see your results.*

---

## ğŸ“ˆ Visualizations

The project generates **7 professional plots**, all saved as `.png` files:

| Plot | File | Description |
|------|------|-------------|
| ğŸ”· Feature Distributions | `feature_distributions.png` | Histograms by species for all 4 features |
| ğŸ”— Correlation Heatmap | `correlation_heatmap.png` | Feature correlation matrix |
| ğŸŒ Pairplot | `pairplot.png` | All feature pair combinations colored by species |
| ğŸ“¦ Boxplots | `boxplots.png` | Feature spread and outliers per species |
| ğŸ† Model Comparison | `model_comparison.png` | Test vs CV accuracy bar chart for all models |
| ğŸ”¢ Confusion Matrices | `confusion_matrices.png` | 4 confusion matrices side by side |
| ğŸŒ³ Feature Importance | `feature_importance.png` | Random Forest feature importance |
| ğŸ—ºï¸ Decision Boundary | `decision_boundary.png` | RF decision boundary (petal features) |

---

## ğŸ’¡ Key Insights

1. **Petal features dominate** â€” `petal_length` and `petal_width` together explain ~95%+ of the class separability
2. **Setosa is trivially separable** â€” linearly separable from other species in petal space
3. **Versicolorâ€“Virginica boundary is the challenge** â€” slight overlap in feature space
4. **Random Forest handles noise best** â€” ensemble averaging reduces boundary errors
5. **No overfitting detected** â€” consistent train/CV scores across all models

---

## ğŸ“ Project Structure

```
CodeAlpha_IrisFlowerClassification/
â”‚
â”œâ”€â”€ ğŸ““ iris_classification.ipynb    â† Main Jupyter Notebook (full pipeline)
â”œâ”€â”€ ğŸ“„ README.md                    â† This file
â”œâ”€â”€ ğŸ“‹ requirements.txt             â† Python dependencies
â”‚
â””â”€â”€ ğŸ“Š Generated Plots/
    â”œâ”€â”€ feature_distributions.png
    â”œâ”€â”€ correlation_heatmap.png
    â”œâ”€â”€ pairplot.png
    â”œâ”€â”€ boxplots.png
    â”œâ”€â”€ model_comparison.png
    â”œâ”€â”€ confusion_matrices.png
    â”œâ”€â”€ feature_importance.png
    â””â”€â”€ decision_boundary.png
```

---

## ğŸš€ How to Run

### Option 1 â€” Clone & Run Locally

```bash
# 1. Clone the repository
git clone https://github.com/YOUR_USERNAME/CodeAlpha_IrisFlowerClassification.git
cd CodeAlpha_IrisFlowerClassification

# 2. Install dependencies
pip install -r requirements.txt

# 3. Launch Jupyter Notebook
jupyter notebook iris_classification.ipynb
```

### Option 2 â€” Run on Google Colab *(No setup needed)*

> Click the badge below to open directly in Google Colab:

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/CodeAlpha_IrisFlowerClassification/blob/main/iris_classification.ipynb)

---

## ğŸ“¦ Requirements

```txt
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
jupyter>=1.0.0
```

Install all at once:
```bash
pip install -r requirements.txt
```

---

## ğŸ“š What I Learned

- How to perform structured EDA with multiple visualization techniques
- Understanding class separability through pairplots and correlation analysis
- Importance of feature scaling (StandardScaler) for KNN and Logistic Regression
- Comparing models objectively using cross-validation vs test accuracy
- How ensemble methods (Random Forest) outperform single models on real datasets

---

## ğŸ”— Connect

<div align="center">

| Platform | Link |
|----------|------|
| ğŸ’¼ LinkedIn | [Your LinkedIn Profile](https://linkedin.com/in/YOUR_USERNAME) |
| ğŸ™ GitHub | [Your GitHub Profile](https://github.com/YOUR_USERNAME) |
| ğŸ¢ Internship | [CodeAlpha](https://www.codealpha.tech) |

</div>

---

<div align="center">

**ğŸŒ¸ Made with â¤ï¸ during the CodeAlpha Data Science Internship**

*If you found this project helpful, please give it a â­ on GitHub!*

</div>
